{
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.12",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4",
   "authorship_tag": "ABX9TyPGA4k9cOvmvn8Q1EXgT0oc"
  },
  "accelerator": "GPU",
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 31259,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.utils.prune as prune\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "# 2. ìœ í‹¸ë¦¬í‹°: ëª¨ë¸ ì‚¬ì´ì¦ˆ(MB) ë° íŒŒë¼ë¯¸í„° ê³„ì‚° í•¨ìˆ˜\n",
    "def get_model_info(model, name=\"Model\"):\n",
    "    # ëª¨ë¸ì„ ì„ì‹œ ì €ì¥í•˜ì—¬ íŒŒì¼ í¬ê¸° ì¸¡ì •\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size_mb = os.path.getsize(\"temp.p\") / 1e6\n",
    "    os.remove(\"temp.p\")\n",
    "\n",
    "    # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚° (0ì´ ì•„ë‹Œ ê²ƒë§Œ)\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    zero_params = sum((p == 0).sum().item() for p in model.parameters())\n",
    "    non_zero_params = total_params - zero_params\n",
    "\n",
    "    print(f\"[{name}] Size: {size_mb:.2f} MB | Non-Zero Params: {non_zero_params:,} (Total: {total_params:,})\")\n",
    "    return size_mb, non_zero_params\n",
    "\n",
    "# 3. ìœ í‹¸ë¦¬í‹°: ì •í™•ë„ í‰ê°€ í•¨ìˆ˜\n",
    "def evaluate(model, loader, device=device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    start_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100 * correct / total\n",
    "    inference_time = (time.time() - start_time) / len(loader.dataset) * 1000 # ms per sample (roughly)\n",
    "    return acc, inference_time"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Data Pipeline: CIFAR-10\n",
    "# Data Normalization: CIFAR-10 ë°ì´í„°ì…‹ì˜ ì±„ë„ë³„ í‰ê· ê³¼ í‘œì¤€í¸ì°¨ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •ê·œí™”.\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "print(\"Loading CIFAR-10 Dataset...\")\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "# Model Architecture: ResNet-18 for CIFAR-10\n",
    "def get_resnet18_cifar():\n",
    "    # ê³µì‹ torchvision ëª¨ë¸ ë¡œë“œ (Pretrained ì•„ë‹˜)\n",
    "    model = torchvision.models.resnet18(weights=None)\n",
    "\n",
    "    # CIFAR-10 ì´ë¯¸ì§€ í¬ê¸°(32x32)ì— ë§ì¶° ì…ë ¥ë‹¨ ìˆ˜ì •\n",
    "    # ì›ë³¸ ResNetì€ 224x224ìš©ì´ë¼ 7x7 convì™€ maxpoolì´ ì •ë³´ë¥¼ ë„ˆë¬´ ë§ì´ ë‚ ë¦¼\n",
    "    model.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "    model.maxpool = nn.Identity() # Maxpool ì œê±°\n",
    "    model.fc = nn.Linear(512, 10) # 10ê°œ í´ë˜ìŠ¤\n",
    "    return model.to(device)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model = get_resnet18_cifar()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15, 25], gamma=0.1)\n",
    "\n",
    "save_dir = \"/\"\n",
    "\n",
    "# ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ\n",
    "checkpoint_path = os.path.join(save_dir, 'checkpoint.pth')\n",
    "best_model_path = os.path.join(save_dir, 'best_baseline.pth')\n",
    "\n",
    "start_epoch = 0\n",
    "best_acc = 0.0\n",
    "\n",
    "# Training Loop: Resume Support\n",
    "if os.path.exists(checkpoint_path):\n",
    "    print(f\"Checkpoint found. Resuming from {checkpoint_path}\")\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    model.load_state_dict(checkpoint['model_state'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state'])\n",
    "    scheduler.load_state_dict(checkpoint['scheduler_state'])\n",
    "    start_epoch = checkpoint['epoch'] + 1\n",
    "    best_acc = checkpoint['best_acc']\n",
    "    print(f\"   Resuming from Epoch {start_epoch}, Current Best Acc: {best_acc:.2f}%\")\n",
    "else:\n",
    "    print(\"Starting Training from Scratch...\")\n",
    "\n",
    "epochs = 30\n",
    "print(\"-\" * 60)\n",
    "for epoch in range(start_epoch, epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    current_acc, _ = evaluate(model, testloader)\n",
    "    avg_loss = running_loss / len(trainloader)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {avg_loss:.4f} | Acc: {current_acc:.2f}%\")\n",
    "\n",
    "    # Best Model ì €ì¥\n",
    "    if current_acc > best_acc:\n",
    "        best_acc = current_acc\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "        print(f\"   New Best Model Saved! ({best_acc:.2f}%)\")\n",
    "\n",
    "    # Checkpoint ì €ì¥ (ë§¤ epoch)\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state': model.state_dict(),\n",
    "        'optimizer_state': optimizer.state_dict(),\n",
    "        'scheduler_state': scheduler.state_dict(),\n",
    "        'best_acc': best_acc\n",
    "    }, checkpoint_path)\n",
    "\n",
    "print(\"-\" * 60)\n",
    "print(f\"Baseline Training Finished. Best Acc: {best_acc:.2f}%\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Baseline ë¡œë“œ.\n",
    "baseline_model = get_resnet18_cifar()\n",
    "baseline_model.load_state_dict(torch.load(best_model_path))\n",
    "base_acc, base_time = evaluate(baseline_model, testloader)\n",
    "base_size, base_nz = get_model_info(baseline_model, \"Baseline\")\n",
    "\n",
    "print(f\"\\nExperiment: Fine-grained Analysis (Focus on 60%~80%)...\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Ratio':^10} | {'Acc (%)':^10} | {'Drop (%)':^10} | {'Params (M)':^12} | {'Status'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Pruning ë¹„ìœ¨ ì •ì˜\n",
    "ratios = [\n",
    "    0.50,\n",
    "    0.60, 0.65,\n",
    "    0.68, 0.70, 0.72, 0.74, 0.75, 0.76, 0.78,\n",
    "    0.80, 0.82, 0.85\n",
    "]\n",
    "\n",
    "results = {'ratio': [], 'acc': [], 'params': []}\n",
    "best_pruned_model = None\n",
    "target_ratio = 0.0\n",
    "\n",
    "for r in ratios:\n",
    "    model_temp = copy.deepcopy(baseline_model)\n",
    "\n",
    "    # Pruning ìˆ˜í–‰\n",
    "    parameters_to_prune = []\n",
    "    for module in model_temp.modules():\n",
    "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "            parameters_to_prune.append((module, 'weight'))\n",
    "\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune,\n",
    "        pruning_method=prune.L1Unstructured,\n",
    "        amount=r,\n",
    "    )\n",
    "\n",
    "    # ë§ˆìŠ¤í¬ ì˜êµ¬ ì ìš©\n",
    "    for module, _ in parameters_to_prune:\n",
    "        prune.remove(module, 'weight')\n",
    "\n",
    "    # í‰ê°€\n",
    "    acc, _ = evaluate(model_temp, testloader)\n",
    "    _, nz_params = get_model_info(model_temp, name=f\"Prune {r}\")\n",
    "\n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    results['ratio'].append(r)\n",
    "    results['acc'].append(acc)\n",
    "    results['params'].append(nz_params)\n",
    "\n",
    "    drop = base_acc - acc\n",
    "\n",
    "    # ìƒíƒœ ë©”ì‹œì§€\n",
    "    if drop < 1.0: status = \"Safe\"\n",
    "    elif drop < 2.0: status = \"Caution\" # 1~2% ë–¨ì–´ì§ (Fine-tuningìœ¼ë¡œ ë³µêµ¬ ê°€ëŠ¥ì„± ë†’ìŒ)\n",
    "    elif drop < 5.0: status = \"Warning\"\n",
    "    else: status = \"Collapse\"\n",
    "\n",
    "    print(f\"{r*100:^9.0f}% | {acc:^10.2f} | {drop:^10.2f} | {nz_params/1e6:^12.2f} | {status}\")\n",
    "\n",
    "    # Best Case ì„ ì • ê¸°ì¤€ ìˆ˜ì •:\n",
    "    # \"ì •í™•ë„ í•˜ë½ì´ 2.0% ë¯¸ë§Œì¸ ê²ƒ ì¤‘ì—ì„œ ê°€ì¥ ë§ì´ ê¹ì€ ê²ƒ\"\n",
    "    # ì´ìœ : ë’¤ì— Fine-tuning(ì¬í™œì¹˜ë£Œ)ì´ ìˆìœ¼ë¯€ë¡œ, 2% ì •ë„ ê¹Œì§„ ê¹ì—¬ë„ ë³µêµ¬ ê°€ëŠ¥í•¨.\n",
    "    if drop < 2.0:\n",
    "        best_pruned_model = copy.deepcopy(model_temp)\n",
    "        target_ratio = r\n",
    "\n",
    "print(\"-\" * 80)\n",
    "print(f\"Best Pruning Ratio Selected: {target_ratio*100:.0f}%\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Fine-tuning Process\n",
    "print(f\"\\nPhase 2.5: Fine-tuning Best Model (Ratio: {target_ratio*100:.0f}%)\")\n",
    "print(\"   -> ê°€ì§€ì¹˜ê¸°ë¡œ ë–¨ì–´ì§„ ì„±ëŠ¥ì„ 5 Epoch ë™ì•ˆ ì§§ê²Œ ì¬í•™ìŠµí•˜ì—¬ ë³µêµ¬í•©ë‹ˆë‹¤.\")\n",
    "\n",
    "# 1. Best Model ë³µì œ (ì¬í•™ìŠµìš©)\n",
    "ft_model = copy.deepcopy(best_pruned_model).to(device)\n",
    "ft_model.train() # í•™ìŠµ ëª¨ë“œ ì „í™˜\n",
    "\n",
    "# 2. ì„¤ì •: ê¸°ì¡´ë³´ë‹¤ ë‚®ì€ Learning Rate\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_ft = optim.SGD(ft_model.parameters(), lr=0.001, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler_ft = optim.lr_scheduler.StepLR(optimizer_ft, step_size=3, gamma=0.1)\n",
    "\n",
    "# 3. Fine-tuning Loop (5 Epochs)\n",
    "ft_epochs = 5\n",
    "ft_losses = []\n",
    "\n",
    "print(\"-\" * 60)\n",
    "for epoch in range(ft_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer_ft.zero_grad()\n",
    "        outputs = ft_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Pruningì„ 'remove'ë¡œ ì˜êµ¬ ì ìš©í•œ ê²½ìš°, 0ê°’ì´ ë¯¸ì„¸í•˜ê²Œ ë³€í•  ìˆ˜ ìˆìŒ.\n",
    "        optimizer_ft.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    scheduler_ft.step()\n",
    "    print(f\"   [Fine-tune] Epoch {epoch+1}/{ft_epochs} | Loss: {running_loss/len(trainloader):.4f}\")\n",
    "\n",
    "# 4. Fine-tuning í›„ í‰ê°€\n",
    "ft_acc, _ = evaluate(ft_model, testloader)\n",
    "ft_size, _ = get_model_info(ft_model, \"Fine-tuned\")\n",
    "\n",
    "# Result Comparison: Pruning ì§í›„ vs Fine-tuning í›„\n",
    "# ì•„ê¹Œ ë¦¬ìŠ¤íŠ¸ì—ì„œ Best Ratioì— í•´ë‹¹í•˜ëŠ” Acc ì°¾ê¸°\n",
    "best_idx = ratios.index(target_ratio)\n",
    "pruned_acc = results['acc'][best_idx]\n",
    "\n",
    "print(\"\\nRecovery Report\")\n",
    "print(f\"   - Before FT (Pruned): {pruned_acc:.2f}%\")\n",
    "print(f\"   - After FT (Retrained): {ft_acc:.2f}%\")\n",
    "print(f\"   - Recovered: +{ft_acc - pruned_acc:.2f}%p\")\n",
    "\n",
    "# PPTìš© í‘œ ì¶œë ¥\n",
    "print(\"\\nPPT Table Data\")\n",
    "print(\"| State | Accuracy | Size (MB) |\")\n",
    "print(\"|-------|----------|-----------|\")\n",
    "print(f\"| Baseline | {base_acc:.2f}% | {base_size:.2f} |\")\n",
    "print(f\"| Pruned   | {pruned_acc:.2f}% | {base_size:.2f} (Sparse) |\")\n",
    "print(f\"| Fine-tuned | {ft_acc:.2f}% | {base_size:.2f} (Sparse) |\")\n",
    "\n",
    "# Best Pruned Modelì„ Fine-tuning ëœ ë†ˆìœ¼ë¡œ êµì²´ (ì´ê±¸ë¡œ Quantization ê°€ì•¼ í•¨)\n",
    "best_pruned_model = ft_model"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 1. Sparsity vs Accuracy ê·¸ë˜í”„ (Collapse Zone í‘œì‹œ)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(np.array(ratios)*100, results['acc'], 'r-o', linewidth=2, label='Pruned Accuracy')\n",
    "plt.axhline(y=base_acc, color='b', linestyle='--', label=f'Baseline ({base_acc:.1f}%)')\n",
    "# Fine-tuning ê²°ê³¼ ì  ì°ê¸°\n",
    "plt.plot(target_ratio*100, ft_acc, 'g*', markersize=15, label=f'After Fine-tuning ({ft_acc:.1f}%)')\n",
    "\n",
    "# Collapse Zone (ì •í™•ë„ 10% ì´ìƒ ë–¨ì–´ì§„ êµ¬ê°„) ìƒ‰ì¹ \n",
    "collapse_threshold = base_acc - 10\n",
    "for i in range(len(ratios)-1):\n",
    "    if results['acc'][i+1] < collapse_threshold:\n",
    "        plt.axvspan(ratios[i]*100, 100, color='gray', alpha=0.2, label='Collapse Zone')\n",
    "        plt.text(ratios[i]*100 + 2, collapse_threshold-5, \"CRITICAL\\nCOLLAPSE\", color='red', fontweight='bold')\n",
    "        break\n",
    "\n",
    "plt.title(f'Sensitivity Analysis: When does the model break?', fontsize=14)\n",
    "plt.xlabel('Sparsity (%)', fontsize=12)\n",
    "plt.ylabel('Accuracy (%)', fontsize=12)\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig('pruning_curve.png', dpi=150)\n",
    "print(\"ê·¸ë˜í”„ ì €ì¥ ì™„ë£Œ: pruning_curve.png\")\n",
    "\n",
    "# 2. Kernel Visualization (ê°€ì¤‘ì¹˜ 0 ëœê±° ë³´ì—¬ì£¼ê¸°)\n",
    "def plot_kernels(tensor, title):\n",
    "    if tensor.dim() == 4: # Conv Layer\n",
    "        weights = tensor.data.cpu().numpy()[:16] # ì²« 16ê°œë§Œ\n",
    "        weights = np.mean(weights, axis=1) # ì±„ë„ í‰ê· \n",
    "    else: return\n",
    "\n",
    "    fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
    "    fig.suptitle(title, fontsize=16)\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        ax.imshow(weights[i], cmap='viridis')\n",
    "        ax.axis('off')\n",
    "    return fig\n",
    "\n",
    "# Baseline vs Pruned ë¹„êµ\n",
    "fig1 = plot_kernels(baseline_model.conv1.weight, \"Original Weights (Dense)\")\n",
    "plt.savefig('kernel_before.png', bbox_inches='tight')\n",
    "\n",
    "# ì£¼ì˜: Fine-tuning í›„ì—ë„ 0ì´ ìœ ì§€ë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ìš©ë„\n",
    "fig2 = plot_kernels(best_pruned_model.conv1.weight, f\"Pruned Weights (Sparsity {target_ratio*100:.0f}%)\")\n",
    "plt.savefig('kernel_after.png', bbox_inches='tight')\n",
    "\n",
    "print(\"ì»¤ë„ ì‹œê°í™” ì €ì¥ ì™„ë£Œ: kernel_before.png, kernel_after.png\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def visualize_sparsity_comparison(model_orig, model_pruned, layer_name=\"layer2.0.conv1\"):\n",
    "    \"\"\"\n",
    "    íŠ¹ì • ë ˆì´ì–´ì˜ ê°€ì¤‘ì¹˜ë¥¼ ê°€ì ¸ì™€ì„œ 0ì´ ëœ ë¶€ë¶„(Pruned)ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # 1. ë ˆì´ì–´ ê°ì²´ ê°€ì ¸ì˜¤ê¸° (ë¬¸ìì—´ ì´ë¦„ìœ¼ë¡œ ì ‘ê·¼)\n",
    "    # ì˜ˆ: layer2ì˜ 0ë²ˆì§¸ ë¸”ë¡ì˜ conv1\n",
    "    layer_orig = dict(model_orig.named_modules())[layer_name]\n",
    "    layer_pruned = dict(model_pruned.named_modules())[layer_name]\n",
    "\n",
    "    # 2. ê°€ì¤‘ì¹˜ ì¶”ì¶œ (CPUë¡œ ì´ë™)\n",
    "    w_orig = layer_orig.weight.data.cpu().numpy()\n",
    "    w_pruned = layer_pruned.weight.data.cpu().numpy()\n",
    "\n",
    "    # 3. ì‹œê°í™”ë¥¼ ìœ„í•´ 4D í…ì„œë¥¼ 2D í–‰ë ¬ë¡œ í¼ì¹˜ê¸°\n",
    "    # (Out_Channel, In_Channel, K, K) -> (Out_Channel, Flattened_Input)\n",
    "    # ì´ë ‡ê²Œ í•˜ë©´ ê°€ì¤‘ì¹˜ ì „ì²´ ë¶„í¬ë¥¼ í•œëˆˆì— ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "    w_orig_flat = w_orig.reshape(w_orig.shape[0], -1)\n",
    "    w_pruned_flat = w_pruned.reshape(w_pruned.shape[0], -1)\n",
    "\n",
    "    # 4. í¬ì†Œì„±(Sparsity) ê³„ì‚°\n",
    "    sparsity = 100 * np.sum(w_pruned == 0) / w_pruned.size\n",
    "\n",
    "    # ================= ê·¸ë¦¬ê¸° =================\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "    # [ì™¼ìª½] ì›ë³¸ ëª¨ë¸\n",
    "    # 0ì´ ì•„ë‹Œ ê°’ë§Œ ìƒ‰ì¹  (ëŒ€ë¶€ë¶„ ê½‰ ì°¨ ìˆìŒ)\n",
    "    axes[0].imshow(np.abs(w_orig_flat), cmap='viridis', aspect='auto', vmin=0, vmax=0.1)\n",
    "    axes[0].set_title(f\"Baseline: {layer_name}\\n(Dense, No Zeros)\", fontsize=14)\n",
    "    axes[0].set_xlabel(\"Input Connections (Flattened)\")\n",
    "    axes[0].set_ylabel(\"Output Filters\")\n",
    "\n",
    "    # [ì˜¤ë¥¸ìª½] Pruned ëª¨ë¸ (í•µì‹¬!)\n",
    "    # 0ì¸ ë¶€ë¶„ì€ 'ê²€ì€ìƒ‰'ìœ¼ë¡œ ë‚˜ì˜´ -> ë§ˆìŠ¤í¬ ì‹œê°í™”\n",
    "    # ê°’ì´ ìˆìœ¼ë©´ 1(í°ìƒ‰/ë…¸ë€ìƒ‰), 0ì´ë©´ 0(ê²€ì€ìƒ‰/ë³´ë¼ìƒ‰)\n",
    "    mask = (w_pruned_flat != 0).astype(float)\n",
    "\n",
    "    axes[1].imshow(mask, cmap='gray', aspect='auto', interpolation='nearest')\n",
    "    axes[1].set_title(f\"Pruned: {layer_name}\\n(Sparsity: {sparsity:.2f}%)\", fontsize=14, color='red')\n",
    "    axes[1].set_xlabel(\"Input Connections (Flattened)\")\n",
    "    axes[1].set_yticks([]) # Yì¶• ë¼ë²¨ ì¤‘ë³µ ì œê±°\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# --- ì‹¤í–‰ ---\n",
    "print(\"ğŸ” Visualizing Layer 2 (Pruningì´ í™œë°œí•œ êµ¬ê°„)...\")\n",
    "# layer1ì€ ë³´í†µ ì¤‘ìš”í•´ì„œ ë§ì´ ë‚¨ê³ , layer2ë‚˜ layer3ë¶€í„° ë§ì´ ì˜ë¦½ë‹ˆë‹¤.\n",
    "visualize_sparsity_comparison(baseline_model, best_pruned_model, layer_name=\"layer2.0.conv1\")\n",
    "\n",
    "print(\"\\nğŸ” Visualizing Layer 3 (ë” ê¹Šì€ êµ¬ê°„)...\")\n",
    "visualize_sparsity_comparison(baseline_model, best_pruned_model, layer_name=\"layer3.0.conv1\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torchvision\n",
    "from torch.nn.quantized import FloatFunctional\n",
    "\n",
    "# 1. ì–‘ìí™” í˜¸í™˜ì´ ê°€ëŠ¥í•œ BasicBlock ì •ì˜\n",
    "class QuantizableBasicBlock(nn.Module):\n",
    "    def __init__(self, original_block):\n",
    "        super(QuantizableBasicBlock, self).__init__()\n",
    "        # ê¸°ì¡´ ê°€ì¤‘ì¹˜ì™€ ì„¤ì •ì„ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤\n",
    "        self.conv1 = original_block.conv1\n",
    "        self.bn1 = original_block.bn1\n",
    "        self.relu = original_block.relu\n",
    "        self.conv2 = original_block.conv2\n",
    "        self.bn2 = original_block.bn2\n",
    "        self.downsample = original_block.downsample\n",
    "        self.stride = original_block.stride\n",
    "\n",
    "        # ë§ì…ˆì„ ìœ„í•œ íŠ¹ìˆ˜ ê°ì²´ ì¶”ê°€\n",
    "        self.skip_add = FloatFunctional()\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # += ì—°ì‚°ì ëŒ€ì‹  FloatFunctional.add ì‚¬ìš©\n",
    "        out = self.skip_add.add(out, identity)\n",
    "\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "# 2. ëª¨ë¸ ë‚´ì˜ ëª¨ë“  BasicBlockì„ êµì²´í•˜ëŠ” í•¨ìˆ˜\n",
    "def replace_resnet_blocks(module):\n",
    "    # ì¬ê·€ì ìœ¼ë¡œ ëª¨ë¸ ë‚´ë¶€ë¥¼ íƒìƒ‰í•˜ë©° BasicBlockì„ êµì²´í•©ë‹ˆë‹¤\n",
    "    for name, child in module.named_children():\n",
    "        if isinstance(child, torchvision.models.resnet.BasicBlock):\n",
    "            setattr(module, name, QuantizableBasicBlock(child))\n",
    "        else:\n",
    "            replace_resnet_blocks(child)\n",
    "\n",
    "print(\"Patching ResNet blocks for Quantization...\")\n",
    "\n",
    "# 1. ëª¨ë¸ ì¤€ë¹„ (Wrapper ì ìš©)\n",
    "original_model = copy.deepcopy(best_pruned_model).to('cpu')\n",
    "model_to_quantize = QuantizedModelWrapper(original_model)\n",
    "\n",
    "# 2. ë¸”ë¡ êµì²´ ì‹¤í–‰ (Prepare ì „ì—)\n",
    "replace_resnet_blocks(model_to_quantize.model_fp32)\n",
    "print(\"ResNet BasicBlocks have been replaced with Quantizable versions.\")\n",
    "\n",
    "model_to_quantize.eval()\n",
    "model_to_quantize.qconfig = torch.quantization.get_default_qconfig('fbgemm')\n",
    "\n",
    "# 3. Fuse (ì„ íƒ ì‚¬í•­)\n",
    "\n",
    "# 4. Prepare\n",
    "print(\"   Preparing model...\")\n",
    "torch.quantization.prepare(model_to_quantize, inplace=True)\n",
    "\n",
    "# 5. Calibration\n",
    "print(\"   Running calibration (feed forward)...\")\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, _) in enumerate(trainloader):\n",
    "        if i >= 50: break\n",
    "        model_to_quantize(inputs.to('cpu'))\n",
    "\n",
    "# 6. Convert\n",
    "print(\"   Converting to INT8...\")\n",
    "model_int8 = torch.quantization.convert(model_to_quantize, inplace=True)\n",
    "\n",
    "# 7. í‰ê°€\n",
    "print(\"   Evaluating quantized model...\")\n",
    "q_acc, q_time = evaluate(model_int8, testloader, device='cpu')\n",
    "q_size, _ = get_model_info(model_int8, \"Quantized\")\n",
    "\n",
    "print(f\"\\nFinal Report\")\n",
    "print(f\"1. Baseline:   Acc={base_acc:.2f}%, Size={base_size:.2f}MB\")\n",
    "print(f\"2. Pruned:     Acc={results['acc'][ratios.index(target_ratio)]:.2f}%, Size={base_size:.2f}MB (Sparse)\")\n",
    "print(f\"3. Quantized:  Acc={q_acc:.2f}%, Size={q_size:.2f}MB\")\n",
    "print(f\" ìµœì¢… ì••ì¶•ë¥ : {base_size/q_size:.2f}ë°° ê°ì†Œ\")\n",
    "print(f\" ì •í™•ë„ ì†ì‹¤: {base_acc - q_acc:.2f}%\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import os\n",
    "\n",
    "# ì €ì¥ ê²½ë¡œ ì„¤ì •\n",
    "save_path = \"resnet_pruned_quantized.pth\"\n",
    "\n",
    "# ëª¨ë¸ ì €ì¥ (JIT Script ë°©ì‹ìœ¼ë¡œ ì €ì¥í•˜ëŠ” ê²ƒì´ í˜¸í™˜ì„±ì— ê°€ì¥ ì¢‹ìŠµë‹ˆë‹¤)\n",
    "# ì–‘ìí™” ëª¨ë¸ì€ êµ¬ì¡°ì™€ íŒŒë¼ë¯¸í„°ê°€ ë¬¶ì—¬ìˆì–´ì„œ torch.jit.scriptë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.\n",
    "print(f\"Saving model to {save_path}...\")\n",
    "\n",
    "# 1. ê°„ë‹¨í•œ ì €ì¥ (State Dict)\n",
    "torch.save(model_int8.state_dict(), save_path)\n",
    "\n",
    "# 2. íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "file_size = os.path.getsize(save_path) / (1024 * 1024)\n",
    "print(f\"Model saved. File Size on Disk: {file_size:.2f} MB\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# ê·¸ë˜í”„ 1: Accuracy vs Pruning Ratio\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(np.array(results['ratio'])*100, results['acc'], 'r-o', label='Pruned Acc')\n",
    "plt.axhline(y=base_acc, color='b', linestyle='--', label='Baseline Acc')\n",
    "plt.axvline(x=target_ratio*100, color='g', linestyle=':', label='Selected Best Point')\n",
    "\n",
    "# ë¶•ê´´ ì§€ì  í‘œì‹œ (ì •í™•ë„ê°€ 10% ì´ìƒ ë–¨ì–´ì§„ ì²« ì§€ì )\n",
    "for r, acc in zip(results['ratio'], results['acc']):\n",
    "    if base_acc - acc > 10:\n",
    "        plt.annotate('Collapse!', xy=(r*100, acc), xytext=(r*100, acc-10),\n",
    "                     arrowprops=dict(facecolor='black', shrink=0.05))\n",
    "        break\n",
    "\n",
    "plt.title('Sensitivity Analysis: Accuracy vs Pruning')\n",
    "plt.xlabel('Pruning Ratio (%)')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# ê·¸ë˜í”„ 2: Parameter Reduction\n",
    "plt.subplot(1, 2, 2)\n",
    "# íŒŒë¼ë¯¸í„° ìˆ˜ë¥¼ ë°±ë§Œ(M) ë‹¨ìœ„ë¡œ ë³€í™˜\n",
    "params_m = np.array(results['params']) / 1e6\n",
    "plt.plot(np.array(results['ratio'])*100, params_m, 'b-s', label='Active Params')\n",
    "plt.title('Parameter Reduction')\n",
    "plt.xlabel('Pruning Ratio (%)')\n",
    "plt.ylabel('Parameters (Millions)')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, 'final_result_graph.png'))\n",
    "plt.show()\n",
    "\n",
    "print(\"ê·¸ë˜í”„ ìƒì„± ì™„ë£Œ! ë°œí‘œ ìë£Œì— ì‚¬ìš©í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import files\n",
    "try:\n",
    "    files.download('resnet_pruned_quantized.pth')\n",
    "    print(\"ë‹¤ìš´ë¡œë“œ ìš”ì²­ ì™„ë£Œ. (ë¸Œë¼ìš°ì € ë‹¤ìš´ë¡œë“œ ì°½ì„ í™•ì¸í•˜ì„¸ìš”)\")\n",
    "except Exception as e:\n",
    "    print(\"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨. ì™¼ìª½ íŒŒì¼ íƒìƒ‰ê¸°ì—ì„œ ìš°í´ë¦­ -> ë‹¤ìš´ë¡œë“œ í•˜ì„¸ìš”.\")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from google.colab import drive\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# 1. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ (ì—°ë™)\n",
    "print(\"Mounting Google Drive...\")\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 2. ì €ì¥í•  ê²½ë¡œ ì„¤ì • (ë‚´ ë“œë¼ì´ë¸Œì˜ ë£¨íŠ¸ ê²½ë¡œ)\n",
    "# ì›í•˜ì‹œëŠ” í´ë”ê°€ ìˆë‹¤ë©´ '/content/drive/MyDrive/í´ë”ëª…/' ìœ¼ë¡œ ìˆ˜ì •í•˜ì„¸ìš”.\n",
    "destination_path = '/content/drive/MyDrive/resnet_pruned_quantized.pth'\n",
    "\n",
    "# 3. íŒŒì¼ ë³µì‚¬ (í˜„ì¬ ìœ„ì¹˜ -> êµ¬ê¸€ ë“œë¼ì´ë¸Œ)\n",
    "source_path = 'resnet_pruned_quantized.pth' # ë°©ê¸ˆ ì €ì¥í•œ ëª¨ë¸ íŒŒì¼\n",
    "\n",
    "if os.path.exists(source_path):\n",
    "    shutil.copy(source_path, destination_path)\n",
    "    print(f\"êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì €ì¥ ì™„ë£Œ. ê²½ë¡œ: {destination_path}\")\n",
    "\n",
    "    # ì˜ ë“¤ì–´ê°”ëŠ”ì§€ íŒŒì¼ í¬ê¸° í™•ì¸\n",
    "    size = os.path.getsize(destination_path) / (1024 * 1024)\n",
    "    print(f\"ì €ì¥ëœ íŒŒì¼ í¬ê¸°: {size:.2f} MB\")\n",
    "else:\n",
    "    print(\"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ìœ„ì—ì„œ ëª¨ë¸ ì €ì¥ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”.\")"
   ]
  }
 ]
}
